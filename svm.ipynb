{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # for handling multi-dimensional array operation\n",
    "import pandas as pd  # for reading data from csv\n",
    "#import statsmodels.api as sm  # for finding the p-value\n",
    "from sklearn.preprocessing import MinMaxScaler  # for normalization\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting dataset into train and test sets...\n"
     ]
    }
   ],
   "source": [
    "# normalizing and pre processing\n",
    "data = pd.read_csv('data/data.csv')\n",
    "diagnosis_map = {'M':1, 'B':-1}\n",
    "data['diagnosis'] = data['diagnosis'].map(diagnosis_map)\n",
    "data.drop(data.columns[[-1, 0]], axis=1, inplace=True)\n",
    "\n",
    "Y = data.loc[:, 'diagnosis']  # all rows of 'diagnosis'\n",
    "X = data.iloc[:, 1:]  # all rows of column 1 and ahead (features)\n",
    "\n",
    "X_normalized = MinMaxScaler().fit_transform(X.values)\n",
    "X = pd.DataFrame(X_normalized)\n",
    "\n",
    "X.insert(loc=len(X.columns), column='intercept', value=1)\n",
    "\n",
    "print(\"splitting dataset into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = tts(X, Y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "            0         1         2         3         4         5         6  \\\n68   0.096928  0.257694  0.103656  0.045387  0.487226  0.373965  0.733365   \n181  0.667755  0.570172  0.683505  0.495228  0.554934  0.809214  0.582709   \n63   0.103744  0.140345  0.106489  0.049799  0.221901  0.208975  0.140300   \n248  0.173648  0.524518  0.167369  0.086320  0.396678  0.162444  0.055740   \n60   0.150930  0.174839  0.143459  0.071432  0.548614  0.187811  0.025398   \n..        ...       ...       ...       ...       ...       ...       ...   \n71   0.090255  0.166723  0.103656  0.042630  0.408053  0.410159  0.201640   \n106  0.220503  0.291512  0.216847  0.114104  0.555836  0.252500  0.165651   \n270  0.345923  0.240446  0.321401  0.207466  0.105263  0.022606  0.016987   \n435  0.331251  0.335137  0.327068  0.193425  0.481809  0.288080  0.263824   \n102  0.246060  0.365573  0.231014  0.133701  0.248262  0.064413  0.055834   \n\n            7         8         9  ...        21        22        23  \\\n68   0.217445  0.530808  0.642376  ...  0.283316  0.075153  0.034285   \n181  0.743539  0.674242  0.505897  ...  0.571962  0.627970  0.467902   \n63   0.108350  0.646970  0.414280  ...  0.192164  0.075601  0.030697   \n248  0.080268  0.422727  0.280750  ...  0.617537  0.137308  0.066482   \n60   0.064115  0.850000  0.413648  ...  0.144723  0.096867  0.045075   \n..        ...       ...       ...  ...       ...       ...       ...   \n71   0.142744  0.425253  0.839090  ...  0.097281  0.060511  0.024381   \n106  0.173211  0.374242  0.320977  ...  0.459488  0.174810  0.082703   \n270  0.031064  0.226263  0.080034  ...  0.230011  0.219284  0.122739   \n435  0.321223  0.307576  0.326032  ...  0.500533  0.316201  0.168133   \n102  0.087972  0.342929  0.143429  ...  0.554904  0.170178  0.089117   \n\n           24        25        26        27        28        29  intercept  \n68   0.508684  0.397018  1.000000  0.601375  0.524936  0.409681          1  \n181  0.514627  0.709327  0.541534  0.997595  0.499310  0.481175          1  \n63   0.179555  0.136324  0.111581  0.174811  0.338459  0.195855          1  \n248  0.519910  0.109158  0.089856  0.210859  0.363493  0.173357          1  \n60   0.371987  0.069244  0.017316  0.088625  0.392667  0.165027          1  \n..        ...       ...       ...       ...       ...       ...        ...  \n71   0.327082  0.209865  0.114537  0.164467  0.135817  0.349993          1  \n106  0.644720  0.231598  0.229473  0.418557  0.244628  0.235668          1  \n270  0.095754  0.022383  0.030879  0.114536  0.176030  0.040404          1  \n435  0.595192  0.319692  0.325000  0.627835  0.318155  0.330972          1  \n102  0.271611  0.059503  0.091454  0.255361  0.222551  0.090122          1  \n\n[455 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>intercept</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>68</th>\n      <td>0.096928</td>\n      <td>0.257694</td>\n      <td>0.103656</td>\n      <td>0.045387</td>\n      <td>0.487226</td>\n      <td>0.373965</td>\n      <td>0.733365</td>\n      <td>0.217445</td>\n      <td>0.530808</td>\n      <td>0.642376</td>\n      <td>...</td>\n      <td>0.283316</td>\n      <td>0.075153</td>\n      <td>0.034285</td>\n      <td>0.508684</td>\n      <td>0.397018</td>\n      <td>1.000000</td>\n      <td>0.601375</td>\n      <td>0.524936</td>\n      <td>0.409681</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>0.667755</td>\n      <td>0.570172</td>\n      <td>0.683505</td>\n      <td>0.495228</td>\n      <td>0.554934</td>\n      <td>0.809214</td>\n      <td>0.582709</td>\n      <td>0.743539</td>\n      <td>0.674242</td>\n      <td>0.505897</td>\n      <td>...</td>\n      <td>0.571962</td>\n      <td>0.627970</td>\n      <td>0.467902</td>\n      <td>0.514627</td>\n      <td>0.709327</td>\n      <td>0.541534</td>\n      <td>0.997595</td>\n      <td>0.499310</td>\n      <td>0.481175</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>0.103744</td>\n      <td>0.140345</td>\n      <td>0.106489</td>\n      <td>0.049799</td>\n      <td>0.221901</td>\n      <td>0.208975</td>\n      <td>0.140300</td>\n      <td>0.108350</td>\n      <td>0.646970</td>\n      <td>0.414280</td>\n      <td>...</td>\n      <td>0.192164</td>\n      <td>0.075601</td>\n      <td>0.030697</td>\n      <td>0.179555</td>\n      <td>0.136324</td>\n      <td>0.111581</td>\n      <td>0.174811</td>\n      <td>0.338459</td>\n      <td>0.195855</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>0.173648</td>\n      <td>0.524518</td>\n      <td>0.167369</td>\n      <td>0.086320</td>\n      <td>0.396678</td>\n      <td>0.162444</td>\n      <td>0.055740</td>\n      <td>0.080268</td>\n      <td>0.422727</td>\n      <td>0.280750</td>\n      <td>...</td>\n      <td>0.617537</td>\n      <td>0.137308</td>\n      <td>0.066482</td>\n      <td>0.519910</td>\n      <td>0.109158</td>\n      <td>0.089856</td>\n      <td>0.210859</td>\n      <td>0.363493</td>\n      <td>0.173357</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>0.150930</td>\n      <td>0.174839</td>\n      <td>0.143459</td>\n      <td>0.071432</td>\n      <td>0.548614</td>\n      <td>0.187811</td>\n      <td>0.025398</td>\n      <td>0.064115</td>\n      <td>0.850000</td>\n      <td>0.413648</td>\n      <td>...</td>\n      <td>0.144723</td>\n      <td>0.096867</td>\n      <td>0.045075</td>\n      <td>0.371987</td>\n      <td>0.069244</td>\n      <td>0.017316</td>\n      <td>0.088625</td>\n      <td>0.392667</td>\n      <td>0.165027</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.090255</td>\n      <td>0.166723</td>\n      <td>0.103656</td>\n      <td>0.042630</td>\n      <td>0.408053</td>\n      <td>0.410159</td>\n      <td>0.201640</td>\n      <td>0.142744</td>\n      <td>0.425253</td>\n      <td>0.839090</td>\n      <td>...</td>\n      <td>0.097281</td>\n      <td>0.060511</td>\n      <td>0.024381</td>\n      <td>0.327082</td>\n      <td>0.209865</td>\n      <td>0.114537</td>\n      <td>0.164467</td>\n      <td>0.135817</td>\n      <td>0.349993</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>0.220503</td>\n      <td>0.291512</td>\n      <td>0.216847</td>\n      <td>0.114104</td>\n      <td>0.555836</td>\n      <td>0.252500</td>\n      <td>0.165651</td>\n      <td>0.173211</td>\n      <td>0.374242</td>\n      <td>0.320977</td>\n      <td>...</td>\n      <td>0.459488</td>\n      <td>0.174810</td>\n      <td>0.082703</td>\n      <td>0.644720</td>\n      <td>0.231598</td>\n      <td>0.229473</td>\n      <td>0.418557</td>\n      <td>0.244628</td>\n      <td>0.235668</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>0.345923</td>\n      <td>0.240446</td>\n      <td>0.321401</td>\n      <td>0.207466</td>\n      <td>0.105263</td>\n      <td>0.022606</td>\n      <td>0.016987</td>\n      <td>0.031064</td>\n      <td>0.226263</td>\n      <td>0.080034</td>\n      <td>...</td>\n      <td>0.230011</td>\n      <td>0.219284</td>\n      <td>0.122739</td>\n      <td>0.095754</td>\n      <td>0.022383</td>\n      <td>0.030879</td>\n      <td>0.114536</td>\n      <td>0.176030</td>\n      <td>0.040404</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>435</th>\n      <td>0.331251</td>\n      <td>0.335137</td>\n      <td>0.327068</td>\n      <td>0.193425</td>\n      <td>0.481809</td>\n      <td>0.288080</td>\n      <td>0.263824</td>\n      <td>0.321223</td>\n      <td>0.307576</td>\n      <td>0.326032</td>\n      <td>...</td>\n      <td>0.500533</td>\n      <td>0.316201</td>\n      <td>0.168133</td>\n      <td>0.595192</td>\n      <td>0.319692</td>\n      <td>0.325000</td>\n      <td>0.627835</td>\n      <td>0.318155</td>\n      <td>0.330972</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>0.246060</td>\n      <td>0.365573</td>\n      <td>0.231014</td>\n      <td>0.133701</td>\n      <td>0.248262</td>\n      <td>0.064413</td>\n      <td>0.055834</td>\n      <td>0.087972</td>\n      <td>0.342929</td>\n      <td>0.143429</td>\n      <td>...</td>\n      <td>0.554904</td>\n      <td>0.170178</td>\n      <td>0.089117</td>\n      <td>0.271611</td>\n      <td>0.059503</td>\n      <td>0.091454</td>\n      <td>0.255361</td>\n      <td>0.222551</td>\n      <td>0.090122</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>455 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "68    -1\n181    1\n63    -1\n248   -1\n60    -1\n      ..\n71    -1\n106   -1\n270   -1\n435    1\n102   -1\nName: diagnosis, Length: 455, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-9aff8f00",
   "language": "python",
   "display_name": "PyCharm (scientificProject)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}